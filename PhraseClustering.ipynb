{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models.keyedvectors as keyedvectors\n",
    "import gensim.models.word2vec as word2vec\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/enwiki_20180420_100d.txt', binary=False, limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_emount = 4     # Количество кластеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_index = 0\n",
    "wordcount = 0\n",
    "sentence_count = 4           \n",
    "sentence_count = min(sentence_count, 11856)\n",
    "sentences_vectors = np.zeros((sentence_count, 100), dtype = 'float32')\n",
    "\n",
    "with open('data/datasetSentences.txt','r') as file: \n",
    "    for i in range(sentence_count): \n",
    "        line = file.readline()\n",
    "        for word in line.split(): \n",
    "            wordcount += 1\n",
    "            if(word.lower() in model.vocab):\n",
    "                 sentences_vectors[sentence_index] += model[word.lower()]\n",
    "                 print(word.lower())\n",
    "\n",
    "        sentences_vectors[sentence_index] = sentences_vectors[sentence_index] / wordcount\n",
    "        sentence_index += 1  \n",
    "        wordcount = 0\n",
    "\n",
    "#print (sentences_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = clusters_emount, random_state=0, n_init=10, max_iter=300)\n",
    "labels = kmeans.fit_predict(sentences_vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/datasetSentences.txt\", \"r\")\n",
    "sentences = f.readlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clusters = [[] for i in range(clusters_emount)]\n",
    "\n",
    "for i in range(sentences_vectors.shape[0]):\n",
    "    j = labels[i]\n",
    "    clusters[j].append(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"super_clusters.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for i in range(len(clusters)):\n",
    "        f.write(\"Cluster \" + str(i) + \":\\n\")\n",
    "        for sentence in clusters[i]:\n",
    "            f.write(sentence)\n",
    "    f.write(\"_______________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}